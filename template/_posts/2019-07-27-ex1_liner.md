---
layout:     post                    # 使用的布局（不需要改）
permalink: /AI/
title:      EX1-liner              # 标题 
subtitle:   p
date:       2019-07-27              # 时间
author:     Supeeeer                # 作者
categories:
    - DeepLearning
catalog: true                       # 是否归档
tags:                               #标签
    - 个人

---



<h1>ex1<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#数据集导入" data-toc-modified-id="数据集导入-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>数据集导入</a></span></li><li><span><a href="#模型假设" data-toc-modified-id="模型假设-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>模型假设</a></span><ul class="toc-item"><li><span><a href="#假设函数-+-代价函数-(正向)" data-toc-modified-id="假设函数-+-代价函数-(正向)-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>假设函数 + 代价函数 (正向)</a></span></li><li><span><a href="#梯度下降函数-(反向)" data-toc-modified-id="梯度下降函数-(反向)-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>梯度下降函数 (反向)</a></span></li></ul></li><li><span><a href="#训练参数" data-toc-modified-id="训练参数-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>训练参数</a></span><ul class="toc-item"><li><span><a href="#数据预处理：提取X，Y-，θ" data-toc-modified-id="数据预处理：提取X，Y-，θ-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>数据预处理：提取X，Y ，θ</a></span></li><li><span><a href="#梯度下降参数" data-toc-modified-id="梯度下降参数-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>梯度下降参数</a></span></li></ul></li><li><span><a href="#绘制拟合图" data-toc-modified-id="绘制拟合图-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>绘制拟合图</a></span></li></ul></div>


```python
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
```

# 数据集导入


```python
path = 'data/ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Population</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.1101</td>
      <td>17.5920</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.5277</td>
      <td>9.1302</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8.5186</td>
      <td>13.6620</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.0032</td>
      <td>11.8540</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.8598</td>
      <td>6.8233</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Population</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>97.000000</td>
      <td>97.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>8.159800</td>
      <td>5.839135</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.869884</td>
      <td>5.510262</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5.026900</td>
      <td>-2.680700</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.707700</td>
      <td>1.986900</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>6.589400</td>
      <td>4.562300</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>8.578100</td>
      <td>7.046700</td>
    </tr>
    <tr>
      <th>max</th>
      <td>22.203000</td>
      <td>24.147000</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
```


![png](ex1_liner_files/ex1_liner_5_0.png)


# 模型假设

## 假设函数 + 代价函数 (正向)

代价函数：$$ J\left( \theta  \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{\left( {h_\theta}\left( {x^{(i)}} \right)-{y^{(i)}}\right)}^2 $$

假设函数：$$ {h_\theta}\left(x \right)={\theta^T}X={\theta_0}+{\theta_1}{x_1} + ... +{\theta_i}{x_i} $$ 


```python
# 此代价函数的参数个数可变
def computeCost(X, y, theta):
    inner = np.power(X * theta.T - y, 2)    # 返回指数运算后的列表
    return np.sum(inner)/(2*len(X))
```

## 梯度下降函数 (反向)
每次都是所有x传入(计算出平均损失值)，更新θ，loss函数应该逐次递减

反复学习同一批数据

梯度下降函数：
$${{\theta }_{j}}:={{\theta }_{j}}-\alpha \frac{\partial }{\partial {{\theta }_{j}}}J\left( \theta  \right)$$


```python
def gradientDescent(X, y, theta, alpha, iters):
    '''
    alpha: 学习率
    iters: 迭代次数
    '''
    temp = np.matrix(np.zeros(theta.shape))
    parameters = int(theta.ravel().shape[1])
    cost = np.zeros(iters)
    
    for i in range(iters):                                       # 训练iters次
        error = (X * theta.T) - y
        
        for j in range(parameters):                              # 计算每一个参数
            term = np.multiply(error, X[:,j]) / len(X)           # dθ = (yi - y) * θ / m
            temp[0,j] = theta[0,j] - (alpha  * np.sum(term))
            
        theta = temp
        cost[i] = computeCost(X, y, theta)                       # 每次训练都返回损失值，检查
        
    return theta, cost
```

for循环效率 < np矩阵相乘

循环：
1. 每个参数 (行)
2. 每个训练集 (列)
3. 每次梯度下降 (不可避免)

# 训练参数

##  数据预处理：提取X，Y ，θ 
每行个数 = x的特征数 = 参数个数

每行值 = 参数系数(参数才是未知数，xy都是固定不变的)

参数初始化设为0


```python
# 将偏置看做一个额外的特征值，其系数为1
data.insert(0, 'Ones', 1)        # 每行的第零个元素插入值为1的数,列名为Ones

cols = data.shape[1]             # 获取列数
X = data.iloc[:,0:cols-1]        # 去掉X最后一列，训练集
y = data.iloc[:,cols-1:cols]     # X最后一列，目标变量

X.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Ones</th>
      <th>Population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>6.1101</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>5.5277</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>8.5186</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>7.0032</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>5.8598</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 转换X和Y为矩阵
X = np.matrix(X.values)
y = np.matrix(y.values)
theta = np.matrix(np.array([0,0]))       # theta 是一个(1,2)矩阵，初始值设为0

print(X.shape, theta.shape, y.shape)
```

    (97, 2) (1, 2) (97, 1)


## 梯度下降参数


```python
# 计算代价函数
computeCost(X, y, theta)
```




    32.072733877455676




```python
# 初始化梯度函数参数
alpha = 0.01
iters = 1000

# 批梯度下降计算参数
g, cost = gradientDescent(X, y, theta, alpha, iters)
print(g)
```

    [[-3.24140214  1.1272942 ]]


# 绘制拟合图


```python
# 模型拟合
x = np.linspace(data.Population.min(), data.Population.max(), 100)
y = g[0, 0] + (g[0, 1] * x)    # 最终模型

fig, ax = plt.subplots(figsize=(12,8))
ax.plot(x, y, 'r', label='Prediction')
ax.scatter(data.Population, data.Profit, label='Traning Data')
ax.legend(loc=2)
ax.set_xlabel('Population')
ax.set_ylabel('Profit')
ax.set_title('Predicted Profit vs. Population Size')
plt.show()
```


![png](ex1_liner_files/ex1_liner_22_0.png)



```python
# 损失函数迭代情况
fig, ax = plt.subplots(figsize=(12,8))
ax.plot(np.arange(iters), cost, 'r')
ax.set_xlabel('Iterations')
ax.set_ylabel('Cost')
ax.set_title('Error vs. Training Epoch')
plt.show()
```


![png](ex1_liner_files/ex1_liner_23_0.png)

